**一、宽依赖和窄依赖**

1.宽依赖

父RDD与子RDD partition之间的关系是一对多。会有shuffle产生 即：父RDD的一个partition数据对应多个子RDD partition 

2.窄依赖

父RDD与子RDD partition之间的关系是一对一。不会有shuffle产生 即：父RDD中的一个partition数据全部都对应到了子RDD 中的一个partition 

![img](E:\Download\YoudaoNote\yangyh11@163.com\54cf533312a6407596e4909302dee9d7\clipboard.png)

**二、Spark任务调度流程**

Spark任务会根据RDD之间的依赖关系，形成一个DAG有向无环图。

DAG会提交给DAGScheduler，DAGScheduler会把DAG划分相互依赖的多个stage。

每个Stage包含一个或多个task任务，然后将这些task以taskSet的形式提交给TaskScheduler运行。

TaskScheduler会遍历每一个taskSet，根据计算数据的位置来分发task到Executor。

Satge切割规则：从后往前，每遇到一个宽依赖，就切割stage

![img](E:\Download\YoudaoNote\yangyh11@163.com\d9d5f01d4b8e4bc88829edc680bd2d9d\clipboard.png)

如图，3个Stage

**三、Stage计算模式**

![img](E:\Download\YoudaoNote\yangyh11@163.com\158cc3c0d4cd442784830e495937d51d\clipboard.png)

1.计算模式

pipeline管道计算模式，迭代器模式 

2.Stage中的数据何时落地

1.shuffle write 2.对RDD进程持久化 

3.Stage并行度（task个数）由谁决定

由Stage中最后一个RDD的partition个数来决定。切片的个数和Stage中间的RDD的partition个数可以影响最终并行度 

4.如何提高Stage的并行度

reduceByKey(fun, num),join(rdd, num) 